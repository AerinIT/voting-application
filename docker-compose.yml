version: '3.9'
services:
  server:
    build:
      context: ./voting-app-server
    container_name: voting-app-server
    ports:
      - "5000:5000"
      - "9464:9464"
    volumes:
      - server-data:/app/data
    environment:
      REDIS_HOST: redis
      REDIS_PORT: 6379
      OTEL_EXPORTER_OTLP_ENDPOINT: http://alloy:12345
    depends_on:
      - redis
      - alloy
    networks:
      - voting-app-network

  client:
    build:
      context: ./voting-app-client
    container_name: voting-app-client
    ports:
      - "3001:3001"
    volumes:
      - client-data:/usr/share/nginx/html
    depends_on:
      - server
    networks:
      - voting-app-network

  redis:
    image: redis:alpine
    container_name: voting-app-redis
    ports:
      - "6379:6379"
    networks:
      - voting-app-network

  nginx:
    image: nginx:alpine
    container_name: voting-app-nginx
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - client
      - server
    networks:
      - voting-app-network

  alloy:
    image: grafana/alloy:latest
    container_name: alloy
    volumes:
      - "./alloy/config.alloy:/etc/alloy/config.alloy"
      - "./alloy/endpoints.json:/etc/alloy/endpoints.json"
    ports:
      - "12345:12345"
      - "12348:12348"
      - "6832:6832"
      - "55679:55679"
    command:
      - run
      - /etc/alloy/config.alloy
      - --server.http.listen-addr=0.0.0.0:12345
      - --storage.path=/var/lib/alloy/data
    depends_on:
      - loki
      - tempo
      - mimir
    networks:
      - voting-app-network

  loki:
    image: grafana/loki:3.2.0
    container_name: loki
    ports:
      - "3100:3100"
    volumes:
      - ./loki/loki-config.yaml:/etc/loki/local-config.yaml
    command: ["--pattern-ingester.enabled=true", "-config.file=/etc/loki/local-config.yaml "]
    networks:
      - voting-app-network

  tempo:
    image: grafana/tempo:2.6.0
    ports:
      - "3200:3200"
      - "4317:4317"
      - "4318:4318"
      - "9411:9411"
      - "55680:55680"
      - "55681:55681"
      - "14250:14250"
    command: [ "-config.file=/etc/tempo-config.yaml" ]
    volumes:
      - "./tempo/tempo-config.yaml:/etc/tempo-config.yaml"
    networks:
      - voting-app-network
  
  mimir:
    image: grafana/mimir:2.13.0
    container_name: mimir
    ports:
      - "9009:9009"
    volumes:
      - ./mimir/mimir-config.yaml:/etc/mimir/mimir-config.yaml
    command: ["-ingester.native-histograms-ingestion-enabled=true", "-config.file=/etc/mimir/mimir-config.yaml"]
    networks:
      - voting-app-network

  grafana:
    image: grafana/grafana:11.2.0
    container_name: grafana
    ports:
      - "3000:3000"
    volumes:
      - "./grafana/definitions:/var/lib/grafana/dashboards"
      - "./grafana/provisioning:/etc/grafana/provisioning"
      - "./grafana/grafana.ini:/etc/grafana/grafana.ini"
    environment:
      - GF_FEATURE_TOGGLES_ENABLE=flameGraph traceqlSearch traceQLStreaming correlations metricsSummary traceqlEditor traceToMetrics traceToProfiles datatrails
      - GF_INSTALL_PLUGINS=grafana-lokiexplore-app,grafana-exploretraces-app,grafana-pyroscope-app
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_AUTH_DISABLE_LOGIN_FORM=true
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    depends_on:
      - mimir
      - loki
      - tempo
    networks:
      - voting-app-network

  k6:
    image: grafana/k6:0.53.0
    volumes:
      - "./k6:/scripts"
    environment:
      - K6_PROMETHEUS_RW_SERVER_URL=http://mimir:9009/api/v1/push
      - K6_DURATION=3600s
      - K6_VUS=4
      - K6_PROMETHEUS_RW_TREND_AS_NATIVE_HISTOGRAM=true
    restart: always
    command: ["run", "-o", "experimental-prometheus-rw", "/scripts/mythical-loadtest.js"]
    networks:
      - voting-app-network

  pyroscope:
    image: grafana/pyroscope:1.8.0
    ports:
      - "4040:4040"
    command: ["server"]
    networks:
      - voting-app-network

  mythical-queue:
    image: rabbitmq:management
    restart: always
    ports:
      - "5672:5672"
      - "15672:15672"
    healthcheck:
      test: rabbitmq-diagnostics check_running
      interval: 5s
      timeout: 30s
      retries: 10
    networks:
      - voting-app-network

  # A postgres DB used to store data by the API server microservice.
  mythical-database:
    image: postgres:14.5
    restart: always
    environment:
      POSTGRES_PASSWORD: "mythical"
    volumes:
      - "postgres-data:/var/lib/postgresql/data"
    ports:
      - "5432:5432"
    networks:
      - voting-app-network

  # A microservice that makes requests to the API server microservice. Requests are also pushed onto the mythical-queue.
  mythical-requester:
    #build:
    #  context: ./source
    #  dockerfile: docker/Dockerfile
    #  args:
    #    SERVICE: mythical-beasts-requester
    image: grafana/intro-to-mltp:mythical-beasts-requester-latest
    restart: always
    depends_on:
      mythical-queue:
        condition: service_healthy
      mythical-server:
        condition: service_started
    ports:
      - "4001:4001"
    environment:
      - NAMESPACE=production
      - LOGS_TARGET=http://alloy:3100/loki/api/v1/push
      - TRACING_COLLECTOR_HOST=alloy
      - TRACING_COLLECTOR_PORT=4317
      - OTEL_EXPORTER_OTLP_TRACES_INSECURE=true
      - OTEL_RESOURCE_ATTRIBUTES=ip=1.2.3.4
      # Uncomment this line to enable timeshift example in the mythical-requester service, which will use timestamps
      # in the log lines themselves to rewrite the default timestamp to the time specified in the logline.
      #- TIMESHIFT=true
    networks:
      - voting-app-network

  # The API server microservice.
  # It writes logs directly to the Loki service, exposes metrics for the Prometheus
  # service and sends traces to the Grafana Alloy instance.
  mythical-server:
    #build:
    #  context: ./source
    #  dockerfile: docker/Dockerfile
    #  args:
    #    SERVICE: mythical-beasts-server
    image: grafana/intro-to-mltp:mythical-beasts-server-latest
    restart: always
    ports:
      - "4000:4000"
      - "8080:80"
    depends_on:
      - mythical-database
    environment:
      - NAMESPACE=production
      - LOGS_TARGET=http://alloy:3100/loki/api/v1/push
      - TRACING_COLLECTOR_HOST=alloy
      - TRACING_COLLECTOR_PORT=4317
      - OTEL_EXPORTER_OTLP_TRACES_INSECURE=true
      - OTEL_RESOURCE_ATTRIBUTES=ip=1.2.3.5
    networks:
      - voting-app-network

  # A microservice that consumes requests from the mythical-queue
  mythical-recorder:
    #build:
    #  context: ./source
    #  dockerfile: docker/Dockerfile
    #  args:
    #    SERVICE: mythical-beasts-recorder
    image: grafana/intro-to-mltp:mythical-beasts-recorder-latest
    restart: always
    depends_on:
      mythical-queue:
        condition: service_healthy
    ports:
      - "4002:4002"
    environment:
      - NAMESPACE=production
      - LOGS_TARGET=http://alloy:3100/loki/api/v1/push
      - TRACING_COLLECTOR_HOST=alloy
      - TRACING_COLLECTOR_PORT=4317
      - OTEL_EXPORTER_OTLP_TRACES_INSECURE=true
      - OTEL_RESOURCE_ATTRIBUTES=ip=1.2.3.5
    networks:
      - voting-app-network

  # The Tempo service stores traces send to it by Grafana Alloy, and takes
  # queries from Grafana to visualise those traces.

  beyla-requester:
    image: grafana/beyla:1.8.4
    # Beyla requires to be run in the same process namespace as the process it's watching.
    # In Docker, we can do this by joining the namespace for the watched process with the Beyla
    # container watching it by using a specific `pid` label.
    pid: "service:mythical-requester"
    # Beyla requires the several system capabilities to run, to add hooks to the underlying kernel.
    # Note that you should *always* be aware of the security implications of adding capabilities
    # before you do so.
    cap_add:
      - SYS_ADMIN
      - SYS_RESOURCE
      - NET_RAW
      - DAC_READ_SEARCH
      - SYS_PTRACE
      - PERFMON
      - BPF
      - CHECKPOINT_RESTORE
    # If using the above capability fails to instrument your service, remove it and uncomment the
    # line below. Beware that this will allow Beyla to run with full privileges, which may be
    # undesirable.
    #privileged: true
    command:
      - /beyla
      - --config=/configs/config.yaml
    volumes:
      - ./beyla/:/configs
    # See the full list of configuration options at
    # https://grafana.com/docs/grafana-cloud/monitor-applications/beyla/configure/options/ for more details on the
    # options set below.
    environment:
      BEYLA_OPEN_PORT: "4001"                                   # Instrument any service listening on port 4001.
      BEYLA_SERVICE_NAMESPACE: "mythical"                       # The namespace for the service.
      BEYLA_PROMETHEUS_PORT: "9090"                             # The port to expose Prometheus metrics on.
      #BEYLA_BPF_TRACK_REQUEST_HEADERS: "true"
      OTEL_SERVICE_NAME: "beyla-mythical-requester"             # The service name to use for OpenTelemetry traces.
      OTEL_EXPORTER_OTLP_TRACES_INSECURE: "true"                # Whether to use an insecure connection to Grafana Alloy.
      OTEL_EXPORTER_OTLP_PROTOCOL: "grpc"                       # The protocol to use to send traces to Grafana Alloy.
      OTEL_EXPORTER_OTLP_TRACES_ENDPOINT: "http://alloy:4317"   # The endpoint to send traces to.
    # The `depends_on` block below ensures that the mythical-requester service is started before Beyla.
    depends_on:
      mythical-requester:
        condition: service_started
    networks:
      - voting-app-network

  beyla-server:
    image: grafana/beyla:1.8.4
    # Beyla requires to be run in the same process namespace as the process it's watching.
    # In Docker, we can do this by joining the namespace for the watched process with the Beyla
    # container watching it by using a specific `pid` label.
    pid: "service:mythical-server"
    # Beyla requires the several system capabilities to run, to add hooks to the underlying kernel.
    # Note that you should *always* be aware of the security implications of adding capabilities
    # before you do so.
    cap_add:
      - SYS_ADMIN
      - SYS_RESOURCE
      - NET_RAW
      - DAC_READ_SEARCH
      - SYS_PTRACE
      - PERFMON
      - BPF
      - CHECKPOINT_RESTORE
    # If using the above capability fails to instrument your service, remove it and uncomment the
    # line below. Beware that this will allow Beyla to run with full privileges, which may be
    # undesirable.
    #privileged: true
    command:
      - /beyla
      - --config=/configs/config.yaml
    volumes:
      - ./beyla/:/configs
    # See the full list of configuration options at
    # https://grafana.com/docs/grafana-cloud/monitor-applications/beyla/configure/options/ for more details on the
    # options set below.
    environment:
      BEYLA_OPEN_PORT: "4000"                                   # Instrument any service listening on port 4000.
      BEYLA_SERVICE_NAMESPACE: "mythical"                       # The namespace for the service.
      BEYLA_PROMETHEUS_PORT: "9090"                             # The port to expose Prometheus metrics on.
      #BEYLA_BPF_TRACK_REQUEST_HEADERS: "true"
      OTEL_SERVICE_NAME: "beyla-mythical-server"                # The service name to use for OpenTelemetry traces.
      OTEL_EXPORTER_OTLP_TRACES_INSECURE: "true"                # Whether to use an insecure connection to Grafana Alloy.
      OTEL_EXPORTER_OTLP_PROTOCOL: "grpc"                       # The protocol to use to send traces to Grafana Alloy.
      OTEL_EXPORTER_OTLP_TRACES_ENDPOINT: "http://alloy:4317"   # The endpoint to send traces to.
    # The `depends_on` block below ensures that the mythical-server service is started before Beyla.
    depends_on:
      mythical-server:
        condition: service_started
    networks:
      - voting-app-network

  beyla-recorder:
    image: grafana/beyla:1.8.4
    # Beyla requires to be run in the same process namespace as the process it's watching.
    # In Docker, we can do this by joining the namespace for the watched process with the Beyla
    # container watching it by using a specific `pid` label.
    pid: "service:mythical-recorder"
    # Beyla requires the several system capabilities to run, to add hooks to the underlying kernel.
    # Note that you should *always* be aware of the security implications of adding capabilities
    # before you do so.
    cap_add:
      - SYS_ADMIN
      - SYS_RESOURCE
      - NET_RAW
      - DAC_READ_SEARCH
      - SYS_PTRACE
      - PERFMON
      - BPF
      - CHECKPOINT_RESTORE
    # If using the above capability fails to instrument your service, remove it and uncomment the
    # line below. Beware that this will allow Beyla to run with full privileges, which may be
    # undesirable.
    #privileged: true
    command:
      - /beyla
      - --config=/configs/config.yaml
    volumes:
      - ./beyla/:/configs
    # See the full list of configuration options at
    # https://grafana.com/docs/grafana-cloud/monitor-applications/beyla/configure/options/ for more details on the
    # options set below.
    environment:
      BEYLA_OPEN_PORT: "4002"                                   # Instrument any service listening on port 4002.
      BEYLA_SERVICE_NAMESPACE: "mythical"                       # The namespace for the service.
      BEYLA_PROMETHEUS_PORT: "9090"                             # The port to expose Prometheus metrics on.
      #BEYLA_BPF_TRACK_REQUEST_HEADERS: "true"
      OTEL_SERVICE_NAME: "beyla-mythical-recorder"              # The service name to use for OpenTelemetry traces.
      OTEL_EXPORTER_OTLP_TRACES_INSECURE: "true"                # Whether to use an insecure connection to Grafana Alloy.
      OTEL_EXPORTER_OTLP_PROTOCOL: "grpc"                       # The protocol to use to send traces to Grafana Alloy.
      OTEL_EXPORTER_OTLP_TRACES_ENDPOINT: "http://alloy:4317"   # The endpoint to send traces to.
    # The `depends_on` block below ensures that the mythical-recorder service is started before Beyla.
    depends_on:
      mythical-recorder:
        condition: service_started
    networks:
    - voting-app-network
       
networks:
  voting-app-network:
    driver: bridge

volumes:
  server-data:
  client-data:
  grafana-data:
  postgres-data:
  tempo-data:
    driver: local